{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e925b6bbdc408aa"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/georgerapeanu/anaconda3/envs/AI2/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/georgerapeanu/anaconda3/envs/AI2/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional\n",
    "\n",
    "from model import UNet\n",
    "from lfw_dataset import LFWDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import transform_generator, inv_transform\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "from utils import eval\n",
    "from train import train\n",
    "import wandb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T08:00:14.184947917Z",
     "start_time": "2024-01-04T08:00:10.314003829Z"
    }
   },
   "id": "332284bc30e487"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5327707e87b8b25b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mgeorgerapeanu\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/georgerapeanu/Desktop/BBU-Computer-Science/Semester5/Computer Vision and Deep Learning/lab4/wandb/run-20240104_100016-ytdhdhwg</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/georgerapeanu/cvdl/runs/ytdhdhwg' target=\"_blank\">breezy-pyramid-13</a></strong> to <a href='https://wandb.ai/georgerapeanu/cvdl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/georgerapeanu/cvdl' target=\"_blank\">https://wandb.ai/georgerapeanu/cvdl</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/georgerapeanu/cvdl/runs/ytdhdhwg' target=\"_blank\">https://wandb.ai/georgerapeanu/cvdl/runs/ytdhdhwg</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/georgerapeanu/cvdl/runs/ytdhdhwg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7fe517ca6710>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"cvdl\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        'NUM_EPOCHS': 10,\n",
    "        'BATCH_SIZE': 128,\n",
    "        'INPUT_SHAPE': (64, 64),\n",
    "        'NUM_LAYERS': 1,\n",
    "        'LR': 0.01\n",
    "    }\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T08:00:22.348679832Z",
     "start_time": "2024-01-04T08:00:14.200440237Z"
    }
   },
   "id": "823785a40aba94f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'NUM_EPOCHS': 10, 'BATCH_SIZE': 128, 'INPUT_SHAPE': [64, 64], 'NUM_LAYERS': 1, 'LR': 0.01}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T08:00:22.349567495Z",
     "start_time": "2024-01-04T08:00:22.319206734Z"
    }
   },
   "id": "a209ed6c9e0101f4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE= 128\n",
    "INPUT_SHAPE = (64, 64)\n",
    "NUM_LAYERS = 2\n",
    "LR = 0.01\n",
    "\n",
    "ARTIFACTS_PATH='./artifacts'\n",
    "BASE_PATH=\"./lfw_dataset\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T08:00:22.433490958Z",
     "start_time": "2024-01-04T08:00:22.333861352Z"
    }
   },
   "id": "dd344063706b1cd9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.9675, Validation Loss: 0.8619\n",
      "Epoch [2/10], Train Loss: 0.8149, Validation Loss: 0.7836\n",
      "Epoch [3/10], Train Loss: 0.7675, Validation Loss: 0.7598\n",
      "Epoch [4/10], Train Loss: 0.7480, Validation Loss: 0.7464\n",
      "Epoch [5/10], Train Loss: 0.7347, Validation Loss: 0.7334\n",
      "Epoch [6/10], Train Loss: 0.7230, Validation Loss: 0.7217\n",
      "Epoch [7/10], Train Loss: 0.7116, Validation Loss: 0.7110\n",
      "Epoch [8/10], Train Loss: 0.6987, Validation Loss: 0.6961\n",
      "Epoch [9/10], Train Loss: 0.6848, Validation Loss: 0.6813\n",
      "Epoch [10/10], Train Loss: 0.6686, Validation Loss: 0.6617\n"
     ]
    },
    {
     "data": {
      "text/plain": "(UNet(\n   (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n   (conv3): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n ),\n {'train': [0.967485174536705,\n   0.8148569415012995,\n   0.7674699227015177,\n   0.7479766656955084,\n   0.7347394873698553,\n   0.7229590366284052,\n   0.7116426626841227,\n   0.6987110475699106,\n   0.6848491579294205,\n   0.6685825089613596],\n  'validation': [0.8618712425231934,\n   0.7836117446422577,\n   0.7597580850124359,\n   0.7463608682155609,\n   0.7334212213754654,\n   0.7216966450214386,\n   0.7110379487276077,\n   0.6960777044296265,\n   0.6813466548919678,\n   0.6616619974374771]})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(None, wandb.config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T08:17:41.074560092Z",
     "start_time": "2024-01-04T08:00:22.350373914Z"
    }
   },
   "id": "19e72edffb7a25b2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "W&B sync reduced upload amount by 26.7%             "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fw_intersection_over_union</td><td>▁▁▁▁▁▁▁▁▃█</td></tr><tr><td>mean_intersection_over_union</td><td>▁▁▁▁▁▁▁▁▃█</td></tr><tr><td>mean_pixel_accuracy</td><td>▁▁▁▁▁▁▁▁▃█</td></tr><tr><td>train_loss</td><td>█▄▃▃▃▂▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▄▄▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fw_intersection_over_union</td><td>0.50571</td></tr><tr><td>mean_intersection_over_union</td><td>0.27541</td></tr><tr><td>mean_pixel_accuracy</td><td>0.37456</td></tr><tr><td>train_loss</td><td>0.66858</td></tr><tr><td>val_loss</td><td>0.66166</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">breezy-pyramid-13</strong> at: <a href='https://wandb.ai/georgerapeanu/cvdl/runs/ytdhdhwg' target=\"_blank\">https://wandb.ai/georgerapeanu/cvdl/runs/ytdhdhwg</a><br/> View job at <a href='https://wandb.ai/georgerapeanu/cvdl/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNzE1MzQxMg==/version_details/v2' target=\"_blank\">https://wandb.ai/georgerapeanu/cvdl/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNzE1MzQxMg==/version_details/v2</a><br/>Synced 6 W&B file(s), 10 media file(s), 11045 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20240104_100016-ytdhdhwg/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T08:18:23.235365458Z",
     "start_time": "2024-01-04T08:17:41.065699347Z"
    }
   },
   "id": "7d2fb092bc62811"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mLFWDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mBASE_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mINPUT_SHAPE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      4\u001B[0m X, y \u001B[38;5;241m=\u001B[39m ds[\u001B[38;5;241m2\u001B[39m]\n",
      "File \u001B[0;32m~/Desktop/BBU-Computer-Science/Semester5/Computer Vision and Deep Learning/lab4/lfw_dataset.py:40\u001B[0m, in \u001B[0;36mLFWDataset.__init__\u001B[0;34m(self, base_folder, transforms, download, split_name)\u001B[0m\n\u001B[1;32m     38\u001B[0m raw_file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbase_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/lfw_funneled/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumber\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     39\u001B[0m feature_file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbase_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/parts_lfw_funneled_gt_images/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumber\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.ppm\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 40\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX\u001B[38;5;241m.\u001B[39mappend(\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_file_path\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mY\u001B[38;5;241m.\u001B[39mappend(cv2\u001B[38;5;241m.\u001B[39mcvtColor(np\u001B[38;5;241m.\u001B[39marray(Image\u001B[38;5;241m.\u001B[39mopen(feature_file_path)), cv2\u001B[38;5;241m.\u001B[39mCOLOR_RGB2BGR))\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transforms \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m :\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ds = LFWDataset(BASE_PATH, transforms=transform_generator(INPUT_SHAPE), split_name='test', download=False)\n",
    "model.eval()\n",
    "\n",
    "X, y = ds[2]\n",
    "model_y = model(X.view(-1, *X.shape))\n",
    "model_y = torch.nn.functional.interpolate(model_y, size=tuple(y.shape))\n",
    "model_y = model_y.view(-1, *y.shape).argmax(dim=0)\n",
    "\n",
    "_, model_y = inv_transform(X, model_y)\n",
    "X, y = inv_transform(X, y)\n",
    "\n",
    "print(X.shape, y.shape, model_y.shape)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(X, cmap='gray')\n",
    "axes[0].set_title('Input')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(model_y, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Output')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(y, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Ground truth')\n",
    "\n",
    "# Remove ticks and labels for a cleaner display\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:19:16.353131127Z",
     "start_time": "2024-01-03T16:19:12.924790894Z"
    }
   },
   "id": "e38bd6ef6aff952"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval(model, LFWDataset(BASE_PATH, transforms=transform_generator(INPUT_SHAPE), download=False, split_name='test'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:19:16.371719979Z",
     "start_time": "2024-01-03T16:19:16.356043204Z"
    }
   },
   "id": "d3f680494f32e892"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds = LFWDataset(BASE_PATH, transforms=transform_generator(INPUT_SHAPE), split_name='validation', download=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-03T16:19:16.362321898Z"
    }
   },
   "id": "9e861649610571"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(ds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-03T16:04:34.218356652Z"
    }
   },
   "id": "c692ef262dd1eba1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds[2][1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-03T16:04:34.218636863Z"
    }
   },
   "id": "d2572ef3ca1cfd09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-03T16:04:34.218915680Z"
    }
   },
   "id": "f36944ff016f6c73"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
