{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e925b6bbdc408aa",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332284bc30e487",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T16:40:54.001754706Z",
     "start_time": "2024-02-24T16:40:52.308702785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/georgerapeanu/miniconda3/envs/AI/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional\n",
    "\n",
    "from model import UNet\n",
    "from lfw_dataset import LFWDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import transform_generator, inv_transform\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "from utils import eval\n",
    "from train import train\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5327707e87b8b25b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T11:43:07.907521379Z",
     "start_time": "2024-01-12T11:43:07.878950902Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "metric = {\n",
    "    'name': 'val_loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'NUM_EPOCHS': {\n",
    "        'values': [10]\n",
    "    },\n",
    "     'BATCH_SIZE': {\n",
    "         'values': [32, 48, 64, 80, 96]\n",
    "      },\n",
    "    'INPUT_SHAPE': {\n",
    "        'values': [(64, 64)]\n",
    "    },\n",
    "    'NUM_LAYERS': {\n",
    "        'values': [2]\n",
    "    },\n",
    "    'LR': {\n",
    "        'values': [0.004, 0.008, 0.01]\n",
    "      },\n",
    "    'INTERMEDIARY_FILTERS': {\n",
    "        'values': [8]\n",
    "    }\n",
    "}\n",
    "\n",
    "# parameters_dict = {\n",
    "#     'NUM_EPOCHS': {\n",
    "#         'values': [10, 20]\n",
    "#     },\n",
    "#      'BATCH_SIZE': {\n",
    "#         # integers between 32 and 256\n",
    "#         # with evenly-distributed logarithms \n",
    "#         'distribution': 'q_log_uniform_values',\n",
    "#         'q': 8,\n",
    "#         'min': 32,\n",
    "#         'max': 96,\n",
    "#       },\n",
    "#     'INPUT_SHAPE': {\n",
    "#         'values': [(64, 64)]\n",
    "#     },\n",
    "#     'NUM_LAYERS': {\n",
    "#         'values': [1, 2]\n",
    "#     },\n",
    "#     'LR': {\n",
    "#         # a flat distribution between 0 and 0.1\n",
    "#         'distribution': 'uniform',\n",
    "#         'min': 0.004,\n",
    "#         'max': 0.04\n",
    "#       },\n",
    "#     'INTERMEDIARY_FILTERS': {\n",
    "#         'values': [8, 16, 32]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f70e21d7b2f1d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T11:43:10.123972032Z",
     "start_time": "2024-01-12T11:43:07.886045411Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: cstsi9oz\n",
      "Sweep URL: https://wandb.ai/georgerapeanu/cvdl/sweeps/cstsi9oz\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"cvdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de6070f3c99a7ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T11:43:10.146594166Z",
     "start_time": "2024-01-12T11:43:10.086467310Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_wandb():\n",
    "    with wandb.init():\n",
    "        train(None, wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ede3949e0e91",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, run_wandb, project=\"cvdl\")RuntimeError: Can't redefine method: forward on class: __torch__.model.___torch_mangle_35.UNet (of Python compilation unit at: 0x5638a008b5a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823785a40aba94f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: georgerapeanu. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\alexa\\Desktop\\cvdl\\wandb\\run-20240113_174925-7g9m2htt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/georgerapeanu/cvdl/runs/7g9m2htt' target=\"_blank\">atomic-sunset-664</a></strong> to <a href='https://wandb.ai/georgerapeanu/cvdl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/georgerapeanu/cvdl' target=\"_blank\">https://wandb.ai/georgerapeanu/cvdl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/georgerapeanu/cvdl/runs/7g9m2htt' target=\"_blank\">https://wandb.ai/georgerapeanu/cvdl/runs/7g9m2htt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/georgerapeanu/cvdl/runs/7g9m2htt?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1b28ca055b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"cvdl\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        'NUM_EPOCHS': 30,\n",
    "        'BATCH_SIZE': 48,\n",
    "        'INPUT_SHAPE': (128, 128),\n",
    "        'NUM_LAYERS': 2,\n",
    "        'LR': 0.004,\n",
    "        'INTERMEDIARY_FILTERS': 32,\n",
    "        'OPTIMIZER': 'Adam'\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a209ed6c9e0101f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T14:20:48.085297833Z",
     "start_time": "2024-01-11T14:20:48.009571374Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NUM_EPOCHS': 10, 'BATCH_SIZE': 32, 'INPUT_SHAPE': [64, 64], 'NUM_LAYERS': 1, 'LR': 0.0713}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd344063706b1cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T15:36:14.702259601Z",
     "start_time": "2024-01-12T15:36:14.669595571Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE= 128\n",
    "INPUT_SHAPE = (64, 64)\n",
    "NUM_LAYERS = 2\n",
    "LR = 0.01\n",
    "\n",
    "ARTIFACTS_PATH='./artifacts'\n",
    "BASE_PATH=\"./lfw_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e72edffb7a25b2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.6673, Validation Loss: 0.5888\n",
      "Epoch [2/30], Train Loss: 0.4759, Validation Loss: 0.5362\n",
      "Epoch [3/30], Train Loss: 0.4283, Validation Loss: 0.7293\n",
      "Epoch [4/30], Train Loss: 0.3908, Validation Loss: 0.4787\n",
      "Epoch [5/30], Train Loss: 0.3735, Validation Loss: 0.6504\n",
      "Epoch [6/30], Train Loss: 0.3548, Validation Loss: 0.6445\n",
      "Epoch [7/30], Train Loss: 0.3263, Validation Loss: 0.4835\n",
      "Epoch [8/30], Train Loss: 0.3072, Validation Loss: 0.3359\n",
      "Epoch [9/30], Train Loss: 0.2871, Validation Loss: 0.4650\n",
      "Epoch [10/30], Train Loss: 0.2850, Validation Loss: 0.3308\n",
      "Epoch [11/30], Train Loss: 0.2622, Validation Loss: 0.3699\n",
      "Epoch [12/30], Train Loss: 0.2444, Validation Loss: 0.3653\n",
      "Epoch [13/30], Train Loss: 0.2359, Validation Loss: 0.3111\n",
      "Epoch [14/30], Train Loss: 0.2320, Validation Loss: 0.2700\n",
      "Epoch [15/30], Train Loss: 0.2234, Validation Loss: 0.2684\n",
      "Epoch [16/30], Train Loss: 0.2131, Validation Loss: 0.2620\n",
      "Epoch [17/30], Train Loss: 0.2080, Validation Loss: 0.2830\n",
      "Epoch [18/30], Train Loss: 0.1992, Validation Loss: 0.2232\n",
      "Epoch [19/30], Train Loss: 0.1945, Validation Loss: 0.2263\n",
      "Epoch [20/30], Train Loss: 0.1914, Validation Loss: 0.2679\n",
      "Epoch [21/30], Train Loss: 0.1847, Validation Loss: 0.2628\n",
      "Epoch [22/30], Train Loss: 0.1861, Validation Loss: 0.2244\n",
      "Epoch [23/30], Train Loss: 0.1850, Validation Loss: 0.2315\n",
      "Epoch [24/30], Train Loss: 0.1794, Validation Loss: 0.2461\n",
      "Epoch [25/30], Train Loss: 0.1739, Validation Loss: 0.2636\n",
      "Epoch [26/30], Train Loss: 0.1674, Validation Loss: 0.2210\n",
      "Epoch [27/30], Train Loss: 0.1649, Validation Loss: 0.2273\n",
      "Epoch [28/30], Train Loss: 0.1631, Validation Loss: 0.2400\n",
      "Epoch [29/30], Train Loss: 0.1613, Validation Loss: 0.2964\n",
      "Epoch [30/30], Train Loss: 0.1614, Validation Loss: 0.2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for artifact model_val_loss to be committed...\n",
      "\n",
      "wandb: Committed artifact georgerapeanu/cvdl/model_val_loss:v425\n",
      "wandb: Waiting for artifact model_mean_pixel_accuracy to be committed...\n",
      "\n",
      "wandb: Committed artifact georgerapeanu/cvdl/model_mean_pixel_accuracy:v348\n",
      "wandb: Waiting for artifact model_mean_intersection_over_union to be committed...\n",
      "\n",
      "wandb: Committed artifact georgerapeanu/cvdl/model_mean_intersection_over_union:v352\n",
      "wandb: Waiting for artifact model_fw_intersection_over_union to be committed...\n",
      "\n",
      "wandb: Committed artifact georgerapeanu/cvdl/model_fw_intersection_over_union:v355\n"
     ]
    }
   ],
   "source": [
    "model = train(None, wandb.config)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cbe906-66c8-497a-9453-00ece46015f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Train Loss: 0.1573, Validation Loss: 0.2443\n",
      "Epoch [2/60], Train Loss: 0.1556, Validation Loss: 0.2409\n",
      "Epoch [3/60], Train Loss: 0.1551, Validation Loss: 0.2387\n",
      "Epoch [4/60], Train Loss: 0.1563, Validation Loss: 0.2356\n",
      "Epoch [5/60], Train Loss: 0.1560, Validation Loss: 0.2312\n",
      "Epoch [6/60], Train Loss: 0.1543, Validation Loss: 0.2335\n",
      "Epoch [7/60], Train Loss: 0.1541, Validation Loss: 0.2306\n",
      "Epoch [8/60], Train Loss: 0.1556, Validation Loss: 0.2269\n",
      "Epoch [9/60], Train Loss: 0.1544, Validation Loss: 0.2360\n",
      "Epoch [10/60], Train Loss: 0.1529, Validation Loss: 0.2368\n",
      "Epoch [11/60], Train Loss: 0.1528, Validation Loss: 0.2341\n",
      "Epoch [12/60], Train Loss: 0.1533, Validation Loss: 0.2274\n",
      "Epoch [13/60], Train Loss: 0.1534, Validation Loss: 0.2306\n",
      "Epoch [14/60], Train Loss: 0.1517, Validation Loss: 0.2268\n",
      "Epoch [15/60], Train Loss: 0.1506, Validation Loss: 0.2322\n",
      "Epoch [16/60], Train Loss: 0.1520, Validation Loss: 0.2345\n",
      "Epoch [17/60], Train Loss: 0.1519, Validation Loss: 0.2286\n",
      "Epoch [18/60], Train Loss: 0.1517, Validation Loss: 0.2341\n",
      "Epoch [19/60], Train Loss: 0.1526, Validation Loss: 0.2292\n",
      "Epoch [20/60], Train Loss: 0.1520, Validation Loss: 0.2265\n",
      "Epoch [21/60], Train Loss: 0.1510, Validation Loss: 0.2349\n",
      "Epoch [22/60], Train Loss: 0.1508, Validation Loss: 0.2293\n",
      "Epoch [23/60], Train Loss: 0.1511, Validation Loss: 0.2317\n",
      "Epoch [24/60], Train Loss: 0.1508, Validation Loss: 0.2333\n",
      "Epoch [25/60], Train Loss: 0.1521, Validation Loss: 0.2257\n",
      "Epoch [26/60], Train Loss: 0.1507, Validation Loss: 0.2280\n",
      "Epoch [27/60], Train Loss: 0.1517, Validation Loss: 0.2239\n",
      "Epoch [28/60], Train Loss: 0.1510, Validation Loss: 0.2315\n",
      "Epoch [29/60], Train Loss: 0.1498, Validation Loss: 0.2262\n",
      "Epoch [30/60], Train Loss: 0.1510, Validation Loss: 0.2277\n",
      "Epoch [31/60], Train Loss: 0.1510, Validation Loss: 0.2277\n",
      "Epoch [32/60], Train Loss: 0.1511, Validation Loss: 0.2230\n",
      "Epoch [33/60], Train Loss: 0.1502, Validation Loss: 0.2240\n",
      "Epoch [34/60], Train Loss: 0.1501, Validation Loss: 0.2291\n",
      "Epoch [35/60], Train Loss: 0.1524, Validation Loss: 0.2285\n",
      "Epoch [36/60], Train Loss: 0.1501, Validation Loss: 0.2315\n",
      "Epoch [37/60], Train Loss: 0.1508, Validation Loss: 0.2236\n",
      "Epoch [38/60], Train Loss: 0.1503, Validation Loss: 0.2216\n",
      "Epoch [39/60], Train Loss: 0.1493, Validation Loss: 0.2265\n",
      "Epoch [40/60], Train Loss: 0.1498, Validation Loss: 0.2266\n",
      "Epoch [41/60], Train Loss: 0.1499, Validation Loss: 0.2284\n",
      "Epoch [42/60], Train Loss: 0.1500, Validation Loss: 0.2310\n",
      "Epoch [43/60], Train Loss: 0.1520, Validation Loss: 0.2236\n",
      "Epoch [44/60], Train Loss: 0.1503, Validation Loss: 0.2239\n",
      "Epoch [45/60], Train Loss: 0.1500, Validation Loss: 0.2237\n",
      "Epoch [46/60], Train Loss: 0.1499, Validation Loss: 0.2250\n",
      "Epoch [47/60], Train Loss: 0.1495, Validation Loss: 0.2269\n",
      "Epoch [48/60], Train Loss: 0.1501, Validation Loss: 0.2213\n",
      "Epoch [49/60], Train Loss: 0.1496, Validation Loss: 0.2244\n",
      "Epoch [50/60], Train Loss: 0.1504, Validation Loss: 0.2198\n",
      "Epoch [51/60], Train Loss: 0.1490, Validation Loss: 0.2225\n",
      "Epoch [52/60], Train Loss: 0.1500, Validation Loss: 0.2312\n",
      "Epoch [53/60], Train Loss: 0.1492, Validation Loss: 0.2330\n",
      "Epoch [54/60], Train Loss: 0.1503, Validation Loss: 0.2249\n",
      "Epoch [55/60], Train Loss: 0.1490, Validation Loss: 0.2241\n"
     ]
    }
   ],
   "source": [
    "model = train(model, {\n",
    "        'NUM_EPOCHS': 60,\n",
    "        'BATCH_SIZE': 48,\n",
    "        'INPUT_SHAPE': (128, 128),\n",
    "        'NUM_LAYERS': 2,\n",
    "        'LR': 0.001,\n",
    "        'INTERMEDIARY_FILTERS': 32,\n",
    "        'OPTIMIZER': 'SGD'\n",
    "    })[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2fb092bc62811",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jumping-violet-653</strong> at: <a href='https://wandb.ai/georgerapeanu/cvdl/runs/n9kr5ch0' target=\"_blank\">https://wandb.ai/georgerapeanu/cvdl/runs/n9kr5ch0</a><br/> View job at <a href='https://wandb.ai/georgerapeanu/cvdl/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyOTcyMDM2OA==/version_details/v6' target=\"_blank\">https://wandb.ai/georgerapeanu/cvdl/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyOTcyMDM2OA==/version_details/v6</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_171655-n9kr5ch0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38bd6ef6aff952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:19:16.353131127Z",
     "start_time": "2024-01-03T16:19:12.924790894Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mLFWDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mBASE_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mINPUT_SHAPE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      4\u001B[0m X, y \u001B[38;5;241m=\u001B[39m ds[\u001B[38;5;241m2\u001B[39m]\n",
      "File \u001B[0;32m~/Desktop/BBU-Computer-Science/Semester5/Computer Vision and Deep Learning/lab4/lfw_dataset.py:40\u001B[0m, in \u001B[0;36mLFWDataset.__init__\u001B[0;34m(self, base_folder, transforms, download, split_name)\u001B[0m\n\u001B[1;32m     38\u001B[0m raw_file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbase_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/lfw_funneled/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumber\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     39\u001B[0m feature_file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbase_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/parts_lfw_funneled_gt_images/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumber\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.ppm\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 40\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX\u001B[38;5;241m.\u001B[39mappend(\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_file_path\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mY\u001B[38;5;241m.\u001B[39mappend(cv2\u001B[38;5;241m.\u001B[39mcvtColor(np\u001B[38;5;241m.\u001B[39marray(Image\u001B[38;5;241m.\u001B[39mopen(feature_file_path)), cv2\u001B[38;5;241m.\u001B[39mCOLOR_RGB2BGR))\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transforms \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m :\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ds = LFWDataset(BASE_PATH, transforms=transform_generator(INPUT_SHAPE), split_name='test', download=False)\n",
    "model.eval()\n",
    "\n",
    "X, y = ds[2]\n",
    "model_y = model(X.view(-1, *X.shape))\n",
    "model_y = torch.nn.functional.interpolate(model_y, size=tuple(y.shape))\n",
    "model_y = model_y.view(-1, *y.shape).argmax(dim=0)\n",
    "\n",
    "_, model_y = inv_transform(X, model_y)\n",
    "X, y = inv_transform(X, y)\n",
    "\n",
    "print(X.shape, y.shape, model_y.shape)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(X, cmap='gray')\n",
    "axes[0].set_title('Input')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(model_y, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Output')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(y, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Ground truth')\n",
    "\n",
    "# Remove ticks and labels for a cleaner display\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f680494f32e892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-03T16:19:16.371719979Z",
     "start_time": "2024-01-03T16:19:16.356043204Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval(model, LFWDataset(BASE_PATH, transforms=transform_generator(INPUT_SHAPE), download=False, split_name='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e861649610571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T15:36:25.453473148Z",
     "start_time": "2024-01-12T15:36:20.985269831Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = LFWDataset(BASE_PATH, transforms=transform_generator(INPUT_SHAPE), split_name='test', download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692ef262dd1eba1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-03T16:04:34.218356652Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2572ef3ca1cfd09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T15:36:41.596249573Z",
     "start_time": "2024-01-12T15:36:41.539060959Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bcd2041b734321",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:38:09.628413987Z",
     "start_time": "2024-01-14T15:38:09.596786471Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"./artifacts/model.h5\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cce2b6c077a79e8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:38:10.934386676Z",
     "start_time": "2024-01-14T15:38:10.758848014Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "scripted_model = torch.jit.script(model)\n",
    "scripted_model.save(\"./artifacts/scripted_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d960eaa6491bf52d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T17:48:39.806985071Z",
     "start_time": "2024-01-12T17:48:38.011461652Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m----> 2\u001B[0m     model_y \u001B[38;5;241m=\u001B[39m model(\u001B[43mds\u001B[49m[\u001B[38;5;241m2\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m*\u001B[39mds[\u001B[38;5;241m2\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape))\n\u001B[1;32m      3\u001B[0m     model_y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39minterpolate(model_y, size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtuple\u001B[39m(ds[\u001B[38;5;241m2\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:]))\n\u001B[1;32m      4\u001B[0m     model_y \u001B[38;5;241m=\u001B[39m model_y\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m*\u001B[39mds[\u001B[38;5;241m2\u001B[39m][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mshape)\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model_y = model(ds[2][0].view(-1, *ds[2][0].shape))\n",
    "    model_y = torch.nn.functional.interpolate(model_y, size=tuple(ds[2][0].shape[1:]))\n",
    "    model_y = model_y.view(-1, *ds[2][1].shape).argmax(dim=0)\n",
    "    X, model_y = inv_transform(ds[2][0], model_y)\n",
    "    X, y = inv_transform(ds[2][0], ds[2][1])\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    \n",
    "    axes[0].imshow(X)\n",
    "    axes[0].set_title('Input')\n",
    "    \n",
    "    axes[1].imshow(cv2.cvtColor(model_y, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title('Output')\n",
    "    \n",
    "    axes[2].imshow(cv2.cvtColor(y, cv2.COLOR_BGR2RGB))\n",
    "    axes[2].set_title('Ground truth')\n",
    "    \n",
    "    # Remove ticks and labels for a cleaner display\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7404f7a66feb3b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T06:50:00.774984165Z",
     "start_time": "2024-01-31T06:50:00.695090665Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './lfw_dataset/parts_train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m train(\u001B[38;5;28;01mNone\u001B[39;00m, {\n\u001B[1;32m      2\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNUM_EPOCHS\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m      3\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBATCH_SIZE\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m48\u001B[39m,\n\u001B[1;32m      4\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINPUT_SHAPE\u001B[39m\u001B[38;5;124m'\u001B[39m: (\u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m128\u001B[39m),\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNUM_LAYERS\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLR\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.001\u001B[39m,\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINTERMEDIARY_FILTERS\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m32\u001B[39m,\n\u001B[1;32m      8\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOPTIMIZER\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSGD\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      9\u001B[0m     })[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Desktop/BBU-Computer-Science/Semester5/Computer Vision and Deep Learning/lab4/train.py:23\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, config)\u001B[0m\n\u001B[1;32m     20\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     21\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 23\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m LFWDataset(BASE_PATH, transforms\u001B[38;5;241m=\u001B[39mtransform_generator(config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINPUT_SHAPE\u001B[39m\u001B[38;5;124m'\u001B[39m]), download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     24\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(train_dataset, batch_size\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBATCH_SIZE\u001B[39m\u001B[38;5;124m'\u001B[39m], shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     25\u001B[0m val_dataset \u001B[38;5;241m=\u001B[39m LFWDataset(BASE_PATH, transforms\u001B[38;5;241m=\u001B[39mtransform_generator(config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINPUT_SHAPE\u001B[39m\u001B[38;5;124m'\u001B[39m]), download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, split_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/BBU-Computer-Science/Semester5/Computer Vision and Deep Learning/lab4/lfw_dataset.py:34\u001B[0m, in \u001B[0;36mLFWDataset.__init__\u001B[0;34m(self, base_folder, transforms, download, split_name)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mY \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbase_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/parts_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msplit_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f:\n\u001B[1;32m     36\u001B[0m         name \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './lfw_dataset/parts_train.txt'"
     ]
    }
   ],
   "source": [
    "model = train(None, {\n",
    "        'NUM_EPOCHS': 1,\n",
    "        'BATCH_SIZE': 48,\n",
    "        'INPUT_SHAPE': (128, 128),\n",
    "        'NUM_LAYERS': 2,\n",
    "        'LR': 0.001,\n",
    "        'INTERMEDIARY_FILTERS': 32,\n",
    "        'OPTIMIZER': 'SGD'\n",
    "    })[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    " model = UNet(in_channels=3, num_layers=2, num_classes=3, intermediary_filters=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T06:48:28.692653187Z",
     "start_time": "2024-01-31T06:48:28.639238630Z"
    }
   },
   "id": "9d132b753684d878"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "total_params = sum(\n",
    "\tparam.numel() for param in model.parameters()\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T06:49:41.024331686Z",
     "start_time": "2024-01-31T06:49:40.978479005Z"
    }
   },
   "id": "18dc4be30b2df8cd",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "478243"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T06:49:43.887614162Z",
     "start_time": "2024-01-31T06:49:43.863469390Z"
    }
   },
   "id": "59ee5d16d9ceaa27",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e726450847c95210"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
