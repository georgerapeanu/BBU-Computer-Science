{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-05T09:50:29.530487691Z",
     "start_time": "2023-12-05T09:50:29.487259178Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import *\n",
    "import torch\n",
    "import itertools\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "import torchsummary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class ChessDataset(torch.utils.data.Dataset):\n",
    "    X: List[Tuple[str, str]]\n",
    "    def __init__(self, base_path: str, split: str, category: str, transform: Callable[[Tuple[str, str]], Tuple[str, str]] =None):\n",
    "        self.__data = []\n",
    "        \n",
    "        with open(f\"{base_path}/{split}.che-eng.{category}.che\", \"r\") as fin, open(f\"{base_path}/{split}.che-eng.{category}.en\", \"r\") as fout:\n",
    "            for line_in, line_out in zip(fin, fout):\n",
    "                tokens_line_in = line_in.strip()\n",
    "                tokens_line_out = line_out.strip()\n",
    "                if transform is not None:\n",
    "                   tokens_line_in, tokens_line_out = transform((tokens_line_in, tokens_line_out))\n",
    "                self.__data.append((tokens_line_in, tokens_line_out))\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.__data)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[List[str], List[str]]:\n",
    "        return self.__data[idx]\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T09:50:29.702586813Z",
     "start_time": "2023-12-05T09:50:29.660957980Z"
    }
   },
   "id": "b06c2aa13b12b520"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Possible idea - add all one-move chess moves"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T09:50:29.888258174Z",
     "start_time": "2023-12-05T09:50:29.874722598Z"
    }
   },
   "id": "46403a0602096f3b"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Vocab&dataloader logic\n",
    "BASE_PATH = \"../dataset\"\n",
    "SPLITS = [\"train\", \"test\", \"valid\"]\n",
    "CATEGORIES = [\"0attack\", \"0score\", \"0simple\", \"1attack\", \"1score\", \"1simple\", \"2.comparitiveattack\", \"2.comparitivescore\", \"2.comparitivesimple\"]\n",
    "\n",
    "target_token_transform = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "train_datasets = [ChessDataset(BASE_PATH, \"train\", category) for category in CATEGORIES]\n",
    "\n",
    "\n",
    "train_iter = itertools.chain.from_iterable(train_datasets)\n",
    "source_vocab = build_vocab_from_iterator(\n",
    "    map(lambda x: x[0].split(\" \"), train_iter),\n",
    "    min_freq=1,\n",
    "    specials=special_symbols,\n",
    "    special_first=True\n",
    ")\n",
    "\n",
    "train_iter = itertools.chain.from_iterable(train_datasets)\n",
    "target_vocab = build_vocab_from_iterator(\n",
    "    map(lambda x: target_token_transform(x[1]), train_iter),\n",
    "    min_freq=1,\n",
    "    specials=special_symbols,\n",
    "    special_first=True\n",
    ")\n",
    "\n",
    "source_vocab.set_default_index(UNK_IDX)\n",
    "target_vocab.set_default_index(UNK_IDX)\n",
    "\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "source_transform = sequential_transforms(\n",
    "    lambda x: x.split(\" \"),\n",
    "    source_vocab,\n",
    "    tensor_transform\n",
    ")\n",
    "\n",
    "target_transform = sequential_transforms(\n",
    "    target_token_transform,\n",
    "    target_vocab,\n",
    "    tensor_transform\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_sample = src_sample.rstrip(\"\\n\")\n",
    "        tgt_sample = tgt_sample.rstrip(\"\\n\")\n",
    "        src_batch.append(source_transform(src_sample))\n",
    "        tgt_batch.append(target_transform(tgt_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "def get_dataloader_for(split, category, batch_size):\n",
    "    return torch.utils.data.DataLoader(ChessDataset(BASE_PATH, split, category), batch_size=batch_size, collate_fn=collate_fn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T09:50:38.661999117Z",
     "start_time": "2023-12-05T09:50:30.446194995Z"
    }
   },
   "id": "5f7bd4c272cdd79f"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "#model\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: torch.Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "    \n",
    "class TokenEmbedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "    \n",
    "class Seq2SeqTransformer(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = torch.nn.Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = torch.nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: torch.Tensor,\n",
    "                trg: torch.Tensor,\n",
    "                src_mask: torch.Tensor,\n",
    "                tgt_mask: torch.Tensor,\n",
    "                src_padding_mask: torch.Tensor,\n",
    "                tgt_padding_mask: torch.Tensor,\n",
    "                memory_key_padding_mask: torch.Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: torch.Tensor, src_mask: torch.Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: torch.Tensor, memory: torch.Tensor, tgt_mask: torch.Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T09:50:38.753299821Z",
     "start_time": "2023-12-05T09:50:38.659428336Z"
    }
   },
   "id": "9fcab90d6cd646a6"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = torch.tril(torch.ones((sz, sz), device=DEVICE))\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T09:50:38.753747660Z",
     "start_time": "2023-12-05T09:50:38.700899240Z"
    }
   },
   "id": "343981185065f0f5"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer, dataloader, loss_fn):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for src, tgt in dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T09:50:38.754018749Z",
     "start_time": "2023-12-05T09:50:38.701137518Z"
    }
   },
   "id": "225b3feedb71cd41"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def train_model_for_category(category: str, transformer = None):\n",
    "    NUM_EPOCHS = 20\n",
    "    torch.manual_seed(0)\n",
    "    SRC_VOCAB_SIZE = len(source_vocab)\n",
    "    TGT_VOCAB_SIZE = len(target_vocab)\n",
    "    EMB_SIZE = 64\n",
    "    NHEAD = 8\n",
    "    FFN_HID_DIM = 512\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_ENCODER_LAYERS = 6\n",
    "    NUM_DECODER_LAYERS = 6\n",
    "    \n",
    "    if transformer is None:\n",
    "        transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                         NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "        \n",
    "        for p in transformer.parameters():\n",
    "            if p.dim() > 1:\n",
    "                torch.nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    val_dataloader = get_dataloader_for( \"valid\", category, BATCH_SIZE)\n",
    "    dataloader = get_dataloader_for( \"train\", category, BATCH_SIZE)\n",
    "    \n",
    "    transformer = transformer.to(DEVICE)\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "    \n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        start_time = timer()\n",
    "        train_loss = train_epoch(transformer, optimizer, dataloader, loss_fn)\n",
    "        end_time = timer()\n",
    "        val_loss = evaluate(transformer, val_dataloader, loss_fn)\n",
    "        print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    return transformer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T09:50:38.754166334Z",
     "start_time": "2023-12-05T09:50:38.713437951Z"
    }
   },
   "id": "effaf6dc250a246d"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 8.313, Val loss: 7.167, Epoch time = 277.964s\n",
      "Epoch: 2, Train loss: 6.496, Val loss: 5.994, Epoch time = 275.455s\n",
      "Epoch: 3, Train loss: 5.838, Val loss: 5.704, Epoch time = 278.229s\n",
      "Epoch: 4, Train loss: 5.543, Val loss: 5.415, Epoch time = 284.291s\n",
      "Epoch: 5, Train loss: 5.264, Val loss: 5.198, Epoch time = 273.903s\n",
      "Epoch: 6, Train loss: 5.072, Val loss: 5.070, Epoch time = 274.134s\n",
      "Epoch: 7, Train loss: 4.942, Val loss: 4.994, Epoch time = 276.574s\n",
      "Epoch: 8, Train loss: 4.841, Val loss: 4.934, Epoch time = 278.236s\n",
      "Epoch: 9, Train loss: 4.760, Val loss: 4.885, Epoch time = 278.315s\n",
      "Epoch: 10, Train loss: 4.691, Val loss: 4.841, Epoch time = 279.259s\n",
      "Epoch: 11, Train loss: 4.631, Val loss: 4.802, Epoch time = 278.183s\n",
      "Epoch: 12, Train loss: 4.577, Val loss: 4.770, Epoch time = 276.015s\n",
      "Epoch: 13, Train loss: 4.528, Val loss: 4.738, Epoch time = 279.090s\n",
      "Epoch: 14, Train loss: 4.484, Val loss: 4.710, Epoch time = 279.158s\n",
      "Epoch: 15, Train loss: 4.445, Val loss: 4.688, Epoch time = 278.464s\n",
      "Epoch: 16, Train loss: 4.409, Val loss: 4.659, Epoch time = 280.401s\n",
      "Epoch: 17, Train loss: 4.376, Val loss: 4.635, Epoch time = 278.265s\n",
      "Epoch: 18, Train loss: 4.344, Val loss: 4.617, Epoch time = 278.345s\n",
      "Epoch: 19, Train loss: 4.315, Val loss: 4.596, Epoch time = 278.027s\n",
      "Epoch: 20, Train loss: 4.287, Val loss: 4.584, Epoch time = 278.447s\n"
     ]
    }
   ],
   "source": [
    "model = train_model_for_category(CATEGORIES[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T11:27:57.408404186Z",
     "start_time": "2023-12-05T09:50:40.303473224Z"
    }
   },
   "id": "c4b54b2e7305ef7d"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T11:50:52.459671776Z",
     "start_time": "2023-12-05T11:50:52.356126806Z"
    }
   },
   "id": "7e304f130e423e2c"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"./save\", \"wb\"))\n",
    "#model = train_model_for_category(CATEGORIES[0], model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T11:50:52.576133595Z",
     "start_time": "2023-12-05T11:50:52.524949982Z"
    }
   },
   "id": "cca922d316c76c18"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    " def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = source_transform(src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(target_vocab.lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T11:50:56.101890044Z",
     "start_time": "2023-12-05T11:50:56.035025155Z"
    }
   },
   "id": "76efe144087b50c6"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "ds = ChessDataset(BASE_PATH, \"test\", CATEGORIES[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T11:51:12.610472046Z",
     "start_time": "2023-12-05T11:51:12.579596292Z"
    }
   },
   "id": "3c71a741c3f7bfc"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "dl = get_dataloader_for(\"test\", CATEGORIES[0], 16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T11:51:12.730505227Z",
     "start_time": "2023-12-05T11:51:12.679822362Z"
    }
   },
   "id": "3929f58cbb307311"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 16])\n"
     ]
    }
   ],
   "source": [
    "for elem in dl:\n",
    "    print(elem[0].shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T11:51:13.237303189Z",
     "start_time": "2023-12-05T11:51:13.213808308Z"
    }
   },
   "id": "d50198fc3cef00df"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black black knight d5 e7 <EOM> <EOMH> 27... Ne7 <EOR> <EOPA> <EOCA>  I take the pawn .  Stops the pawn and hopes for an exchange and maybe a pawn ...\n",
      "black black pawn h7 h5 <EOM> <EOMH> 17... h5 <EOR> white bishop <EOPA> <EOCA>  I take the pawn .  White can now no longer afford any passive move anymore , Black has a pawn phalanx marching straight toward the king , backed by a queen and a rook .\n",
      "white white knight f5 h6 <EOM> <EOMH> 23. Nh6 <EOR> <EOPA> black pawn black queen <EOCA>  I take the knight .  Will trade back my rook I lost for a minor piece earlier .\n",
      "white white knight f7 d8 check <EOM> <EOMH> 22. Nd8+ <EOR> black queen black rook black king <EOPA> <EOCA>  I take the knight .  need to remove his rook off the f file and temporarily put his b rook out of action .\n",
      "white white queen d2 h6 check capture black knight <EOM> <EOMH> 27. Qxh6+ <EOR> <EOPA> black pawn black king black pawn <EOCA>  I take the knight .  queen moves up .\n",
      "white white knight g1 f3 <EOM> <EOMH> 5. Ngf3 <EOR> <EOPA> black knight <EOCA>  I take the pawn .  white to force trade or back up knight\n",
      "black black queen d8 d6 <EOM> <EOMH> 9... Qd6 <EOR> <EOPA> <EOCA>  I take the pawn .  black moves queen up to backup bishop and possible check and attack at whites front row .\n",
      "white white pawn e4 e5 <EOM> <EOMH> 11. e5 <EOR> black knight black bishop <EOPA> black pawn black knight <EOCA>  I take the pawn .  Qf3 but this ties the Q to the e-pawn 's defence and pins the pawn against the Q , reducing its scope for involvement in attack .\n",
      "white white queen d1 e2 <EOM> <EOMH> 16. Qe2 <EOR> <EOPA> black pawn <EOCA>  I take the pawn .  The Q avoids the threatened discovered attack and bolsters the defence of the e-pawn .\n",
      "black black queen b6 c7 <EOM> <EOMH> 17... Qc7 <EOR> <EOPA> white pawn <EOCA>  I take the pawn .  Black relieves the pin and renews the attack on the e-pawn\n",
      "black black knight c6 b4 <EOM> <EOMH> 20... Nb4 <EOR> <EOPA> white pawn <EOCA>  I take the knight .  Bf4 and pile up pressure with 22 .\n",
      "black black queen c6 g2 check capture white pawn <EOM> <EOMH> 26... Qxg2+ <EOR> white knight <EOPA> white rook white king white pawn white pawn white queen <EOCA>  I take the knight .  Rf8 Rxf8 30 .\n",
      "black black queen c6 g2 check capture white pawn <EOM> <EOMH> 26... Qxg2+ <EOR> white knight <EOPA> white rook white king white pawn white pawn white queen <EOCA>  I take the knight .  Nf4 e5 37 .\n",
      "black black pawn e7 e5 <EOM> <EOMH> 1... e5 <EOR> <EOPA> <EOCA>  I take the pawn .  I start my favorite opening which is the king 's pawn opening .\n",
      "white white pawn e2 e4 <EOM> <EOMH> 3. e4 <EOR> <EOPA> <EOCA>  I take the pawn .  Finally , he returned the king 's pawn opening .\n",
      "black black pawn d7 d6 <EOM> <EOMH> 6... d6 <EOR> <EOPA> <EOCA>  I take the pawn .  I free my light-square bishop .\n",
      "black black knight g4 h6 capture white pawn <EOM> <EOMH> 9... Nxh6 <EOR> white queen <EOPA> <EOCA>  I take the pawn .  I take the free pawn .\n",
      "black black knight h6 f5 capture white bishop <EOM> <EOMH> 12... Nhxf5 <EOR> white rook <EOPA> <EOCA>  I take the knight .  I take it with my knight .\n",
      "black black pawn d5 e4 capture white knight <EOM> <EOMH> 17... dxe4 <EOR> white pawn <EOPA> white pawn <EOCA>  I take the pawn .  I take his knight .\n",
      "white white pawn d2 d4 <EOM> <EOMH> 1. d4 <EOR> <EOPA> <EOCA>  I take the pawn .  Moving my pawn out\n",
      "white white knight g1 f3 <EOM> <EOMH> 2. Nf3 <EOR> <EOPA> <EOCA>  I take the pawn .  I move out my knight\n",
      "white white pawn e2 e3 <EOM> <EOMH> 4. e3 <EOR> <EOPA> <EOCA>  I take the pawn .  Protecting my other pawn\n",
      "white white queen h5 e2 <EOM> <EOMH> 6. Qe2 <EOR> black pawn <EOPA> <EOCA>  I take the pawn .  Moving my queen out of danger\n",
      "white white queen e2 h5 check <EOM> <EOMH> 7. Qh5+ <EOR> <EOPA> black pawn black pawn black king <EOCA>  I take the knight .  Putting the king in check again\n",
      "black black knight g6 h4 <EOM> <EOMH> 8... Nh4 <EOR> <EOPA> white pawn <EOCA>  I take the pawn .  Moving the knight ...\n",
      "white white queen e2 h5 check <EOM> <EOMH> 9. Qh5+ <EOR> <EOPA> black knight black pawn black pawn black king <EOCA>  I take the knight .  Putting the king in check again\n",
      "white white bishop f1 b5 check <EOM> <EOMH> 10. Bb5+ <EOR> <EOPA> black king <EOCA>  I take the knight .  Checking the king again\n",
      "white white bishop b5 d3 <EOM> <EOMH> 11. Bd3 <EOR> black pawn <EOPA> black pawn <EOCA>  I take the pawn .  Moving my bishop out of danger\n",
      "white white knight d2 f3 <EOM> <EOMH> 13. Nf3 <EOR> <EOPA> <EOCA>  I take the pawn .  Moving my knight farther out into play\n",
      "white white bishop d3 g6 check capture black pawn <EOM> <EOMH> 18. Bxg6+ <EOR> black queen <EOPA> black king <EOCA>  I take the knight .  Taking the pawn and checking the king\n",
      "black black king e8 d8 <EOM> <EOMH> 18... Kd8 <EOR> white bishop <EOPA> <EOCA>  I take the knight .  Moving out of check\n",
      "white white bishop f4 g5 check <EOM> <EOMH> 19. Bg5+ <EOR> black queen black pawn <EOPA> black king <EOCA>  I take the knight .  Putting the king in check again\n",
      "white white bishop g5 f4 check <EOM> <EOMH> 22. Bf4+ <EOR> <EOPA> black king <EOCA>  I take the knight .  Putting the king in check\n",
      "black black king c7 b6 <EOM> <EOMH> 22... Kb6 <EOR> white bishop <EOPA> <EOCA>  I take the knight .  Moving out of check\n",
      "black black rook a8 b8 capture white bishop <EOM> <EOMH> 23... Rxb8 <EOR> <EOPA> <EOCA>  I take the knight .  Rook takes my bishop\n",
      "white white bishop g6 d3 <EOM> <EOMH> 24. Bd3 <EOR> black rook <EOPA> black pawn <EOCA>  I take the knight .  Moving the bishop out of danger .\n",
      "black black rook g8 g2 capture white pawn <EOM> <EOMH> 24... Rxg2 <EOR> <EOPA> white pawn white pawn <EOCA>  I take the pawn .  Taking my unprotected pawn\n",
      "white white pawn b2 c3 capture black pawn <EOM> <EOMH> 27. bxc3 <EOR> black pawn <EOPA> black bishop <EOCA>  I take the pawn .  I take his pawn\n",
      "white white king e1 e2 <EOM> <EOMH> 28. Ke2 <EOR> black bishop <EOPA> <EOCA>  I take the knight .  Moving out of check\n",
      "black black rook g2 g4 <EOM> <EOMH> 28... Rg4 <EOR> <EOPA> <EOCA>  I take the knight .  Moving the rook into play again .\n",
      "white white rook c1 c3 capture black bishop <EOM> <EOMH> 31. Rxc3 <EOR> <EOPA> black pawn <EOCA>  I take the knight .  I take the unprotected bishop\n",
      "white white king e2 d2 <EOM> <EOMH> 33. Kd2 <EOR> black bishop <EOPA> <EOCA>  I take the pawn .  Moving out of check\n",
      "white white rook c3 c5 capture black pawn <EOM> <EOMH> 34. Rxc5 <EOR> <EOPA> black pawn black pawn <EOCA>  I take the pawn .  I take the pawn\n",
      "white white king d2 c3 <EOM> <EOMH> 35. Kc3 <EOR> black rook <EOPA> <EOCA>  I take the knight .  Moving out of check\n",
      "white white rook c5 b5 check capture black pawn <EOM> <EOMH> 36. Rxb5+ <EOR> black king <EOPA> black pawn black king <EOCA>  I take the knight .  I take the pawn and check the king\n",
      "black black king b6 c6 <EOM> <EOMH> 36... Kc6 <EOR> white rook <EOPA> white rook <EOCA>  I take the knight .  Moving out of check\n",
      "white white rook a1 a2 capture black rook <EOM> <EOMH> 37. Rxa2 <EOR> black rook <EOPA> black rook <EOCA>  I take the knight .  I take the rook\n",
      "black black king c6 d7 <EOM> <EOMH> 38... Kd7 <EOR> white knight <EOPA> <EOCA>  I take the knight .  Moving out of check\n",
      "white white rook b5 d5 check capture black pawn <EOM> <EOMH> 39. Rxd5+ <EOR> <EOPA> black king <EOCA>  I take the knight .  I take the pawn and check the king again\n",
      "black black king d7 c8 <EOM> <EOMH> 39... Kc8 <EOR> white rook <EOPA> <EOCA>  I take the knight .  Moving out of check\n",
      "white white rook d5 c5 check <EOM> <EOMH> 40. Rc5+ <EOR> <EOPA> black king <EOCA>  I take the knight .  Checking the king again\n",
      "black black king c8 b8 <EOM> <EOMH> 40... Kb8 <EOR> white rook <EOPA> <EOCA>  I take the knight .  Moving out of check\n",
      "white white knight d4 c6 check <EOM> <EOMH> 41. Nc6+ <EOR> <EOPA> black pawn black king <EOCA>  I take the knight .  Checking the king again and aiming for the pawn\n",
      "black black king b8 a8 <EOM> <EOMH> 41... Ka8 <EOR> white knight <EOPA> <EOCA>  I take the knight .  Moving out of check while still protecting the pawn\n",
      "white white rook c5 f5 capture black bishop <EOM> <EOMH> 43. Rxf5 <EOR> <EOPA> <EOCA>  I take the knight .  I take the bishop\n",
      "white white rook f5 a5 check capture black pawn <EOM> <EOMH> 44. Rxa5+ <EOR> <EOPA> black rook black king <EOCA>  I take the knight .  I take the pawn , checking the king and deciding to trade my rook for his .\n",
      "black black king b8 c8 <EOM> <EOMH> 46... Kc8 <EOR> white knight <EOPA> <EOCA>  I take the knight .  Moving out of check\n",
      "white white knight c6 e7 check <EOM> <EOMH> 47. Ne7+ <EOR> <EOPA> black king <EOCA>  I take the knight .  Checking the king again\n",
      "black black king c8 d7 <EOM> <EOMH> 47... Kd7 <EOR> white knight <EOPA> white knight <EOCA>  I take the knight .  Moving out of check\n",
      "white white knight e7 g6 <EOM> <EOMH> 48. Ng6 <EOR> black king <EOPA> <EOCA>  I take the pawn .  Moving out of danger and protecting the pawn\n",
      "white white king c3 d4 <EOM> <EOMH> 49. Kd4 <EOR> <EOPA> <EOCA>  I take the pawn .  Moving my king to try and prevent that .\n",
      "white white knight g6 e5 <EOM> <EOMH> 50. Ne5 <EOR> black king <EOPA> <EOCA>  I take the pawn .  Moving my knight out of danger\n",
      "black black king h3 g4 <EOM> <EOMH> 53... Kg4 <EOR> <EOPA> white pawn <EOCA>  I take the knight .  Threatening my pawn again\n",
      "white white pawn h5 h6 <EOM> <EOMH> 54. h6 <EOR> black king <EOPA> <EOCA>  I take the knight .  Moving the pawn again\n",
      "black black king g4 h5 <EOM> <EOMH> 54... Kh5 <EOR> <EOPA> white knight white pawn <EOCA>  I take the knight .  Threatening the pawn again\n",
      "white white queen h8 g7 check <EOM> <EOMH> 57. Qg7+ <EOR> <EOPA> black king <EOCA>  I take the knight .  Putting the king in check\n",
      "black black king g5 h4 <EOM> <EOMH> 57... Kh4 <EOR> white queen <EOPA> <EOCA>  I take the knight .  Moving out of check\n",
      "white white king d5 e5 <EOM> <EOMH> 58. Ke5 <EOR> <EOPA> <EOCA>  I take the pawn .  Bringing my king closer\n",
      "white white king e5 f4 <EOM> <EOMH> 59. Kf4 <EOR> <EOPA> <EOCA>  I take the knight .  Moving the king closer\n",
      "white white queen g7 g3 check <EOM> <EOMH> 60. Qg3+ <EOR> <EOPA> black king <EOCA>  I take the knight .  Putting the king in check\n",
      "white white queen g3 h3 check <EOM> <EOMH> 61. Qh3+ <EOR> <EOPA> black king <EOCA>  I take the knight .  Putting the king in check again\n",
      "white white king f4 f3 <EOM> <EOMH> 65. Kf3 <EOR> <EOPA> <EOCA>  I take the knight .  Moving the king closer to provide support to mate .\n",
      "white white knight e5 g6 <EOM> <EOMH> 15. Ng6 <EOR> black knight <EOPA> black bishop black rook <EOCA>  I take the knight .  Qxg6 19.hxg6 Nd5 with the following 20.Rxe7+ !\n",
      "black black bishop e7 f8 <EOM> <EOMH> 16... Bf8 <EOR> white knight white knight <EOPA> <EOCA>  I take the knight .  16 ... fxg6 leads to 17.Nxg7+ Kf7 18.Qxg6+ ... pending 19.Nxe6+ ... Lastly , 16 ... exf5 and 17.Nxe7 Nxe7 and 18.Bd6 ... 1-0\n",
      "white white pawn a5 b6 capture black pawn <EOM> <EOMH> 9. axb6 <EOR> black pawn black knight <EOPA> black pawn black pawn <EOCA>  I take the pawn .  ... axb6 10 .\n",
      "black black knight c6 a7 <EOM> <EOMH> 14... Na7 <EOR> white bishop white pawn <EOPA> white pawn <EOCA>  I take the pawn .  Forgetting the pin I mistakenly move to attack the pawn .\n",
      "white white king d2 c2 <EOM> <EOMH> 33. Kc2 <EOR> black queen <EOPA> <EOCA>  I take the knight .  Kd1 Nxc3+ 34 .\n",
      "black black queen e4 c2 check <EOM> <EOMH> 36... Qc2+ <EOR> <EOPA> white rook white pawn white king white pawn <EOCA>  I take the knight .  The first check forces his King to move to a3 .\n",
      "black black bishop e7 b4 check capture white rook <EOM> <EOMH> 38... Bxb4+ <EOR> <EOPA> white king white pawn <EOCA>  I take the knight .  And the third check .\n",
      "white white pawn d4 d5 <EOM> <EOMH> 42. d5 <EOR> <EOPA> <EOCA>  I take the pawn .  This is a questionable move , allowing me to fork his King , Rook , and d5 pawn by playing ... Qd2+ .\n",
      "black black knight g8 e7 <EOM> <EOMH> 3... Nge7 <EOR> <EOPA> <EOCA>  I take the pawn .  Maintains protection of the King 's pawn by protecting the threatened knight with the other knight .\n",
      "white white knight b1 c3 <EOM> <EOMH> 5. Nc3 <EOR> <EOPA> <EOCA>  I take the pawn .  White developes another piece with a subtle threat of d5 threatening the supporting knight .\n",
      "black black pawn c7 c6 <EOM> <EOMH> 12... c6 <EOR> white knight <EOPA> white knight <EOCA>  I take the pawn .  Black tries to drive the knight away and open a diagonal for his queen to bindside the white attack .\n",
      "black black queen b6 c7 <EOM> <EOMH> 15... Qc7 <EOR> <EOPA> <EOCA>  I take the pawn .  Moving the king away from the bishop results in the Bishop being instantly lost .\n",
      "black black rook f8 e8 <EOM> <EOMH> 11... Re8 <EOR> <EOPA> white pawn <EOCA>  I take the pawn .  O-O h4 14 .\n",
      "black black queen d8 c7 <EOM> <EOMH> 13... Qc7 <EOR> <EOPA> <EOCA>  I take the pawn .  Qd2 Nh7 [ ?\n",
      "black black queen d8 c7 <EOM> <EOMH> 13... Qc7 <EOR> <EOPA> <EOCA>  I take the pawn .  Qd2 N8h7 15 .\n",
      "white white queen d2 g5 <EOM> <EOMH> 7. Qg5 <EOR> <EOPA> black pawn black knight black pawn <EOCA>  I take the pawn .  Threatening a poisoned pawn .\n",
      "black black knight c6 d4 capture white pawn <EOM> <EOMH> 11... Nxd4 <EOR> <EOPA> white pawn white knight <EOCA>  I take the pawn .  Loses his knight for a pawn .\n",
      "white white pawn d2 d4 <EOM> <EOMH> 3. d4 <EOR> <EOPA> black pawn <EOCA>  I take the pawn .  I expect the usual pawn trade ...\n",
      "white white bishop c1 e3 <EOM> <EOMH> 6. Be3 <EOR> <EOPA> black pawn <EOCA>  I take the pawn .  Development with an additional attack on the undefended c5 pawn ...\n",
      "black black king e8 g8 kingside castling <EOM> <EOMH> 5... O-O <EOR> <EOPA> <EOCA>  I take the pawn .  The text covers White 's planned intrusion and develops the Rook .\n",
      "white white pawn d3 d4 <EOM> <EOMH> 12. d4 <EOR> <EOPA> black bishop black pawn <EOCA>  I take the pawn .  Bxe3 13. fxe3 gives White a substantial center which will frustrate Black 's control and threaten the Knight and King with O-O later .\n",
      "white white king g2 g3 <EOM> <EOMH> 28. Kg3 <EOR> black knight <EOPA> black knight <EOCA>  I take the knight .  Gives away any remaining advantage to the ensuing Knight fork .\n",
      "black black queen d3 d2 <EOM> <EOMH> 35... Qd2 <EOR> <EOPA> white rook white pawn <EOCA>  I take the knight .  Bxc3 Kxc3 38 .\n",
      "white white king g1 f2 <EOM> <EOMH> 32. Kf2 <EOR> <EOPA> <EOCA>  I take the knight .  I 'm getting my king to the centre .\n",
      "black black knight e7 f5 <EOM> <EOMH> 21... Nf5 <EOR> <EOPA> white pawn white bishop <EOCA>  I take the pawn .  Alternative variation : 21 ... e5 22. h4+ Kh5 23 .\n",
      "white white queen f3 h5 check <EOM> <EOMH> 15. Qh5+ <EOR> <EOPA> black bishop black king <EOCA>  I take the knight .  And black resigns .\n",
      "black black pawn e7 e6 <EOM> <EOMH> 5... e6 <EOR> <EOPA> <EOCA>  I take the pawn .  after e4 the bishop has nowhere to go .\n",
      "white white knight g1 f3 <EOM> <EOMH> 2. Nf3 <EOR> <EOPA> <EOCA>  I take the pawn .  Nf3 - I thought of the usual d4 but decided to develop a piece , namely my king knight .\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100):\n",
    "    print(ds[i][0], translate(model, ds[i][0]), ds[i][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T11:51:19.234957742Z",
     "start_time": "2023-12-05T11:51:13.810775252Z"
    }
   },
   "id": "3917db419b68274e"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "'black black pawn h7 h5 <EOM> <EOMH> 17... h5 <EOR> white bishop <EOPA> <EOCA>'"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:02:00.011799587Z",
     "start_time": "2023-11-28T17:01:59.941022247Z"
    }
   },
   "id": "36c3b3b8769b4793"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7b554d9ef7577a8f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
