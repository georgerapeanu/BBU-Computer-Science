{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:51:35.800047303Z",
     "start_time": "2023-11-28T15:51:35.733688989Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import *\n",
    "import torch\n",
    "import itertools\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "import torchsummary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class ChessDataset(torch.utils.data.Dataset):\n",
    "    X: List[Tuple[str, str]]\n",
    "    def __init__(self, base_path: str, split: str, category: str, transform: Callable[[Tuple[str, str]], Tuple[str, str]] =None):\n",
    "        self.__data = []\n",
    "        \n",
    "        with open(f\"{base_path}/{split}.che-eng.{category}.che\", \"r\") as fin, open(f\"{base_path}/{split}.che-eng.{category}.en\", \"r\") as fout:\n",
    "            for line_in, line_out in zip(fin, fout):\n",
    "                tokens_line_in = line_in.strip()\n",
    "                tokens_line_out = line_out.strip()\n",
    "                if transform is not None:\n",
    "                   tokens_line_in, tokens_line_out = transform((tokens_line_in, tokens_line_out))\n",
    "                self.__data.append((tokens_line_in, tokens_line_out))\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.__data)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[List[str], List[str]]:\n",
    "        return self.__data[idx]\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:50:04.494708395Z",
     "start_time": "2023-11-28T15:50:04.464893144Z"
    }
   },
   "id": "b06c2aa13b12b520"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Possible idea - add all one-move chess moves"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:50:04.528427909Z",
     "start_time": "2023-11-28T15:50:04.486492876Z"
    }
   },
   "id": "46403a0602096f3b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Vocab&dataloader logic\n",
    "BASE_PATH = \"../dataset\"\n",
    "SPLITS = [\"train\", \"test\", \"valid\"]\n",
    "CATEGORIES = [\"0attack\", \"0score\", \"0simple\", \"1attack\", \"1score\", \"1simple\", \"2.comparitiveattack\", \"2.comparitivescore\", \"2.comparitivesimple\"]\n",
    "\n",
    "target_token_transform = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "train_datasets = [ChessDataset(BASE_PATH, \"train\", category) for category in CATEGORIES]\n",
    "\n",
    "\n",
    "train_iter = itertools.chain.from_iterable(train_datasets)\n",
    "source_vocab = build_vocab_from_iterator(\n",
    "    map(lambda x: x[0].split(\" \"), train_iter),\n",
    "    min_freq=1,\n",
    "    specials=special_symbols,\n",
    "    special_first=True\n",
    ")\n",
    "\n",
    "train_iter = itertools.chain.from_iterable(train_datasets)\n",
    "target_vocab = build_vocab_from_iterator(\n",
    "    map(lambda x: x[1].split(\" \"), train_iter),\n",
    "    min_freq=1,\n",
    "    specials=special_symbols,\n",
    "    special_first=True\n",
    ")\n",
    "\n",
    "source_vocab.set_default_index(UNK_IDX)\n",
    "target_vocab.set_default_index(UNK_IDX)\n",
    "\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "source_transform = sequential_transforms(\n",
    "    lambda x: x.split(\" \"),\n",
    "    source_vocab,\n",
    "    tensor_transform\n",
    ")\n",
    "\n",
    "target_transform = sequential_transforms(\n",
    "    target_token_transform,\n",
    "    target_vocab,\n",
    "    tensor_transform\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_sample = src_sample.rstrip(\"\\n\")\n",
    "        tgt_sample = tgt_sample.rstrip(\"\\n\")\n",
    "        src_batch.append(source_transform(src_sample))\n",
    "        tgt_batch.append(target_transform(tgt_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "def get_dataloader_for(category, split, batch_size):\n",
    "    return torch.utils.data.DataLoader(ChessDataset(BASE_PATH, category, split), batch_size=batch_size, collate_fn=collate_fn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:50:07.916762801Z",
     "start_time": "2023-11-28T15:50:04.510857345Z"
    }
   },
   "id": "5f7bd4c272cdd79f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#model\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: torch.Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "    \n",
    "class TokenEmbedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "    \n",
    "class Seq2SeqTransformer(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = torch.nn.Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = torch.nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: torch.Tensor,\n",
    "                trg: torch.Tensor,\n",
    "                src_mask: torch.Tensor,\n",
    "                tgt_mask: torch.Tensor,\n",
    "                src_padding_mask: torch.Tensor,\n",
    "                tgt_padding_mask: torch.Tensor,\n",
    "                memory_key_padding_mask: torch.Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: torch.Tensor, src_mask: torch.Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: torch.Tensor, memory: torch.Tensor, tgt_mask: torch.Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:50:07.963709017Z",
     "start_time": "2023-11-28T15:50:07.922380687Z"
    }
   },
   "id": "9fcab90d6cd646a6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:50:07.991672397Z",
     "start_time": "2023-11-28T15:50:07.956637811Z"
    }
   },
   "id": "343981185065f0f5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer, dataloader, loss_fn):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for src, tgt in dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T15:50:08.024872129Z",
     "start_time": "2023-11-28T15:50:07.969463038Z"
    }
   },
   "id": "225b3feedb71cd41"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def train_model_for_category(category: str):\n",
    "    NUM_EPOCHS = 18\n",
    "    torch.manual_seed(0)\n",
    "    SRC_VOCAB_SIZE = len(source_vocab)\n",
    "    TGT_VOCAB_SIZE = len(target_vocab)\n",
    "    EMB_SIZE = 32\n",
    "    NHEAD = 8\n",
    "    FFN_HID_DIM = 64\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_ENCODER_LAYERS = 3\n",
    "    NUM_DECODER_LAYERS = 3\n",
    "    \n",
    "    transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                     NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "    \n",
    "    val_dataloader = get_dataloader_for( \"valid\", category, BATCH_SIZE)\n",
    "    dataloader = get_dataloader_for( \"train\", category, BATCH_SIZE)\n",
    "    \n",
    "    for p in transformer.parameters():\n",
    "        if p.dim() > 1:\n",
    "            torch.nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    transformer = transformer.to(DEVICE)\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "    \n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        start_time = timer()\n",
    "        train_loss = train_epoch(transformer, optimizer, dataloader, loss_fn)\n",
    "        end_time = timer()\n",
    "        val_loss = evaluate(transformer, val_dataloader, loss_fn)\n",
    "        print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    return transformer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:03:06.803721106Z",
     "start_time": "2023-11-28T17:03:06.789026313Z"
    }
   },
   "id": "effaf6dc250a246d"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/georgerapeanu/Desktop/BBU-Computer-Science/Semester5/Research Project/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 8.949, Val loss: 8.225, Epoch time = 170.502s\n",
      "Epoch: 2, Train loss: 7.710, Val loss: 7.043, Epoch time = 169.242s\n",
      "Epoch: 3, Train loss: 6.715, Val loss: 6.190, Epoch time = 168.430s\n",
      "Epoch: 4, Train loss: 6.102, Val loss: 5.761, Epoch time = 167.855s\n",
      "Epoch: 5, Train loss: 5.853, Val loss: 5.618, Epoch time = 168.114s\n",
      "Epoch: 6, Train loss: 5.740, Val loss: 5.482, Epoch time = 168.184s\n",
      "Epoch: 7, Train loss: 5.596, Val loss: 5.321, Epoch time = 168.001s\n",
      "Epoch: 8, Train loss: 5.439, Val loss: 5.164, Epoch time = 168.315s\n",
      "Epoch: 9, Train loss: 5.291, Val loss: 5.031, Epoch time = 167.942s\n",
      "Epoch: 10, Train loss: 5.168, Val loss: 4.926, Epoch time = 165.777s\n",
      "Epoch: 11, Train loss: 5.071, Val loss: 4.846, Epoch time = 168.670s\n",
      "Epoch: 12, Train loss: 4.992, Val loss: 4.783, Epoch time = 168.516s\n",
      "Epoch: 13, Train loss: 4.928, Val loss: 4.731, Epoch time = 168.491s\n",
      "Epoch: 14, Train loss: 4.873, Val loss: 4.687, Epoch time = 167.528s\n",
      "Epoch: 15, Train loss: 4.825, Val loss: 4.650, Epoch time = 167.600s\n",
      "Epoch: 16, Train loss: 4.782, Val loss: 4.617, Epoch time = 169.188s\n",
      "Epoch: 17, Train loss: 4.742, Val loss: 4.586, Epoch time = 169.105s\n",
      "Epoch: 18, Train loss: 4.704, Val loss: 4.558, Epoch time = 168.689s\n"
     ]
    }
   ],
   "source": [
    "model = train_model_for_category(CATEGORIES[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:56:33.140703010Z",
     "start_time": "2023-11-28T17:03:08.409081833Z"
    }
   },
   "id": "c4b54b2e7305ef7d"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = source_transform(src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(target_vocab.lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T18:18:25.084533049Z",
     "start_time": "2023-11-28T18:18:25.071527893Z"
    }
   },
   "id": "76efe144087b50c6"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "ds = ChessDataset(BASE_PATH, \"test\", CATEGORIES[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T18:18:25.665634612Z",
     "start_time": "2023-11-28T18:18:25.637034192Z"
    }
   },
   "id": "3c71a741c3f7bfc"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "' I take the knight . '"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(model, ds[2241][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T18:18:42.675803441Z",
     "start_time": "2023-11-28T18:18:42.590413682Z"
    }
   },
   "id": "3929f58cbb307311"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "'Will trade back my rook I lost for a minor piece earlier .'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[2][1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T18:18:27.201004912Z",
     "start_time": "2023-11-28T18:18:27.172967872Z"
    }
   },
   "id": "d50198fc3cef00df"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "'white white knight f5 h6 <EOM> <EOMH> 23. Nh6 <EOR> <EOPA> black pawn black queen <EOCA>'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[2][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T18:18:27.834446046Z",
     "start_time": "2023-11-28T18:18:27.814354510Z"
    }
   },
   "id": "3917db419b68274e"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "'black black pawn h7 h5 <EOM> <EOMH> 17... h5 <EOR> white bishop <EOPA> <EOCA>'"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:02:00.011799587Z",
     "start_time": "2023-11-28T17:01:59.941022247Z"
    }
   },
   "id": "36c3b3b8769b4793"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7b554d9ef7577a8f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
